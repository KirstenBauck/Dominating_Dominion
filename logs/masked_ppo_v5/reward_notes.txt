def calculate_reward(self):
    """Calculate the reward function for agent"""        
    reward = 0

    # Calculate victory points gained from buying card
    bought = self.game.player_list()[self.learning_player_index].stats['bought']
    gained = self.game.player_list()[self.learning_player_index].stats['gained']
    victory_points_gained = (
        bought.count('Province') * 6 +
        bought.count('Duchy') * 3 +
        bought.count('Estate') * 1 -
        gained.count('Curse') * 1
    )

    # Rewards for termination
    if self.terminated:
        # Rewards for if agent won
        final_score_agent = self.game.player_list()[self.learning_player_index].get_score()
        final_score_bot = self.game.player_list()[1].get_score()
        n_turns = self.game.player_list()[self.learning_player_index].turn_number
        win_reward = 25

        if self._who_won():
            reward += ((victory_points_gained + win_reward) + (final_score_agent) - (n_turns*4) + ((final_score_agent - final_score_bot)*2))
            self.debug_output("Agent won!")
        else:
            reward += ((victory_points_gained - win_reward) + (final_score_agent) - (n_turns*4) + ((final_score_agent - final_score_bot)*2))
            self.debug_output("Agent lost :(")
        
        self.debug_output(f"Final scores are, AGENT({final_score_agent}), BOT({final_score_bot}), and reward is: {reward}")

    # Otherwise incremental rewards
    else:
        # Reward victory points bought during turn
        reward += victory_points_gained

        # Encourage increasing buying power
        total_coppers = self._count_card_type("Copper")
        total_silvers = self._count_card_type("Silver")
        total_golds = self._count_card_type("Gold")
        reward += total_silvers * 0.5
        reward += total_golds * 1
        # A slight penalty for too many coppers (deck clog)
        reward -= max(0, total_coppers - 7) * 0.3

        # Reward using more actions and buys by end of turn
        if self.game.current_player.phase == Phase.NONE and self.current_player_index == self.learning_player_index:
            reward += self.game.current_player._used_buys * 1
            reward += self.game.current_player._used_actions * 0.4

    return reward

################## ENDING TURN HAND ######################
Copper=8
Silver=10
Estate=11
Moat=3
Cellar=1

Total points: 11 (bot = 51)
Number of turns: ~25
Game Over: Province pile is empty

NOTES: 
 - This is the first iteration where the agent played against the big money bot

 - All graphs look good, note that it looks like training only need to occur till about 300,000 timesteps
##########################################################